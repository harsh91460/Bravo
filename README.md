# Bravo ‚Äì Competitive Coding Challenge Platform (LLM-Powered)

**Bravo** is a web-based **competitive coding platform** built to make programming practice **interactive, social, and challenge-driven**, rather than isolated and monotonous. The platform focuses on **head-to-head competition**, allowing users to challenge friends, solve problems under time constraints, and improve through direct performance comparison.

Unlike traditional coding platforms that emphasize solo problem solving, Bravo is designed to **simulate real competitive programming scenarios** in a controlled, game-like environment. The primary goal is to encourage consistent practice, sharpen logical thinking, and provide measurable improvement through competition.

---
![home page](https://github.com/user-attachments/assets/cc679fb0-f531-4bfd-8872-f4989a3c1124)

## üöÄ Key Features

* **1v1 Friend-Based Coding Challenges**
  Compete directly with friends in time-bound coding matches.

* **Online Code Editor**
  Write and submit code directly on the platform with support for multiple programming languages.

* **Automated Code Evaluation**
  Submissions are evaluated against predefined test cases with instant verdicts such as Accepted, Wrong Answer, or Runtime Error.

* **Competitive Match Flow**
  Challenges are designed to test speed, accuracy, and problem-solving efficiency under pressure.

* **Scoreboard & Performance Tracking**
  Track wins, losses, and overall performance across multiple matches.

* **Game-Inspired Experience**
  Competitive structure influenced by multiplayer gaming mechanics to keep users engaged.

---
<img width="1878" height="915" alt="image" src="https://github.com/user-attachments/assets/36791126-3ba7-4c64-9f49-4a5ed0415fa6" />
<img width="1897" height="910" alt="image" src="https://github.com/user-attachments/assets/584f6302-85e7-4da7-aebc-3c176d510f73" />



## üß† LLM Integration (AI Mentor)

Bravo integrates a **Large Language Model (LLM)** to improve the learning experience without encouraging cheating.

* Provides clear and structured **problem explanations**
* Generates **context-aware hints** instead of full solutions
* Analyzes submitted code to identify **logical mistakes**
* Explains *why* a solution fails, not just that it fails
* Suggests conceptual improvements and optimization strategies

The LLM acts as an **AI mentor**, demonstrating reasoning patterns rather than outputting ready-made answers.

---
<img width="1882" height="908" alt="image" src="https://github.com/user-attachments/assets/f89c2a1a-8f95-483d-ab5a-e65601f22e3b" />


## üéØ Project Goals

* Make coding practice competitive, interactive, and engaging
* Encourage consistent problem-solving through social challenges
* Simulate real contest-like conditions for skill development
* Improve logical thinking and decision-making under time pressure

---

## üõ†Ô∏è Tech Stack

* **Frontend:** *To be added*
* **Backend:** *To be added*
* **Database:** *To be added*
* **Code Execution Engine:** *To be added*
* **LLM API:** *To be added*
* **Authentication:** *To be added*

---

## üìå Project Status

* Core competitive features implemented
* LLM-based feedback system under continuous improvement
* Ongoing work on performance, scalability, and evaluation accuracy

---

## üîÆ Future Enhancements

* Multiplayer contests beyond 1v1
* Global leaderboard system
* Custom problem creation
* Anti-cheat mechanisms
* Advanced AI-driven performance analytics
